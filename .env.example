# Server Configuration
PORT=3000
LOG_LEVEL=info
# Debugging (comma-separated list of namespaces)
# Available: mcp:server, mcp:sse, mcp:webhook, mcp:n8n, mcp:tool
DEBUG=mcp:*

# n8n Integration (Required)
# The base URL of your n8n instance
N8N_API_BASE_URL=https://n8n.example.com/api/v1
# Your n8n API Key
N8N_API_KEY=your_n8n_api_key_here

# Security
# Bearer token for MCP clients (e.g. n8n AI Agent) to authenticate with MARCUS
MCP_BEARER_TOKEN=your_secure_token_here

# AI Configuration
# The model to use for coding tasks (n8n analysis, JSON generation)
# Defaults to "qwen/qwen-2.5-coder-32b-instruct" if not set.
# Examples: "anthropic/claude-3.5-sonnet", "openai/gpt-4o"
LLM_MODEL_CODING=qwen/qwen-2.5-coder-32b-instruct
